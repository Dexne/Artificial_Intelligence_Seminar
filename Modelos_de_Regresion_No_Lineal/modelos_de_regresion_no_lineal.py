# -*- coding: utf-8 -*-
"""Modelos_de_Regresion_No_Lineal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12QtbjkTCHpMkM80j_ZZPcq71fIULE-Y4
"""

# Modelos de regresi√≥n no lineal

# Importamos los modulos y librerias
import numpy as np
import numpy.random as rnd
import matplotlib.pyplot as plt
np.random.seed(42)
m = 300
r = 0.5
ruido = r*np.random.randn(m,1)
x = 6* np.random.rand(m,1) - 3
y = 0.5 * x**2 + x + 2 + ruido

from sklearn.model_selection import train_test_split
# Realizamos el corte para los train y test
xtrain, xtest, ytrain, ytest = train_test_split(x,y)
plt.plot(xtrain, ytrain, "b.")#train
plt.plot(xtest, ytest,"r.")#test
plt.xlabel("$x$", fontsize=18)
plt.ylabel("$y$", fontsize=18)
plt.axis([-3,3,0,10])
plt.show()

from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor(max_depth=4)
model.fit(xtrain, ytrain)

print('Train: ', model.score(xtrain,ytrain))
print('Test: ', model.score(xtest,ytest))

x_new = np.linspace(-3,3,50).reshape(-1,1)
y_pred = model.predict(x_new)

plt.plot(x_new,y_pred,'k-', linewidth=3)
plt.plot(xtrain,ytrain,"b.")
plt.plot(xtest,ytest,"r.")
plt.xlabel("$x$", fontsize=18)
plt.ylabel("$y$", fontsize=18)
plt.axis([-3,3,0,10])
plt.show()
#Train:  0.9557573622964591
#Test:  0.9581648798214173

from sklearn.neighbors import KNeighborsRegressor
model = KNeighborsRegressor(n_neighbors=15, weights='uniform')
model.fit(xtrain, ytrain)

print('Train: ', model.score(xtrain, ytrain))
print('Test: ', model.score(xtest, ytest))

x_new = np.linspace(-3,3,100).reshape(-1,1)
y_pred = model.predict(x_new)

plt.plot(x_new, y_pred, 'k-', linewidth=3)
plt.plot(xtrain, ytrain, "b.")
plt.plot(xtest, ytest, "r.")
plt.xlabel("$x$", fontsize=18)
plt.ylabel("$y$", fontsize=18)
plt.axis([-3,3,0,10])
plt.show()

from sklearn.svm import SVR
model = SVR(gamma='scale', C=10, epsilon=0.1, kernel='rbf')
model.fit(xtrain, ytrain.ravel())

print('Train: ', model.score(xtrain, ytrain.ravel()))
print('Test: ', model.score(xtest, ytest.ravel()))

x_new = np.linspace(-3,3,100).reshape(-1,1)
y_pred = model.predict(x_new)

plt.plot(x_new, y_pred, 'k-', linewidth=3)
plt.plot(xtrain, ytrain, "b.")
plt.plot(xtest, ytest, "r.")
plt.xlabel("$x$", fontsize=18)
plt.ylabel("$y$", fontsize=18)
plt.axis([-3,3,0,10])
plt.show()
#Train:  0.9541969014125328
#Test:  0.9667922107451523

from sklearn.kernel_ridge import KernelRidge
model = KernelRidge(alpha=0.1, kernel='rbf')
model.fit(xtrain, ytrain.ravel())

print('Train: ', model.score(xtrain, ytrain.ravel()))
print('Test: ', model.score(xtest, ytest.ravel()))

x_new = np.linspace(-3,3,100).reshape(-1,1)
y_pred = model.predict(x_new)

plt.plot(x_new, y_pred, 'k-', linewidth=3)
plt.plot(xtrain, ytrain, "b.")
plt.plot(xtest, ytest, "r.")
plt.xlabel("$x$", fontsize=18)
plt.ylabel("$y$", fontsize=18)
plt.axis([-3,3,0,10])
plt.show()
#Train:  0.9552385775592783
#Test:  0.965997562574727

from sklearn.neural_network import MLPRegressor
model = MLPRegressor(hidden_layer_sizes=(100,20),
                     solver='adam', activation='relu', batch_size=10)
model.fit(xtrain, ytrain.ravel())

print('Train: ', model.score(xtrain, ytrain.ravel()))
print('Test: ', model.score(xtest, ytest.ravel()))

x_new = np.linspace(-3,3,100).reshape(-1,1)
y_pred = model.predict(x_new)

plt.plot(x_new, y_pred, 'k-', linewidth=3)
plt.plot(xtrain, ytrain, "b.")
plt.plot(xtest, ytest, "r.")
plt.xlabel("$x$", fontsize=18)
plt.ylabel("$y$", fontsize=18)
plt.axis([-3,3,0,10])
plt.show()
#Train:  0.9539750962641953
#Test:  0.9645906250255463

